{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import statsmodels.regression.linear_model as lm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "First, we create $\\mathbf{y}$, the feature we would like to predict, as the normalized average of responses to questions 1-15 on the survey. Those questions include, for example, \"Secret organizations communicate with extraterrestrials, but keep this fact from the public\" and \"The spread of certain viruses and/or diseases is the result of the deliberate, concealed efforts of some organization\", and participants are asked to respond with their level of agreement from 1 to 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['E1', 'E2', 'E3', 'E4', 'E5', 'E6', 'E7', 'E8', 'E9', 'E10', 'E11',\n",
       "       'E12', 'E13', 'E14', 'E15', 'introelapse', 'testelapse', 'surveyelapse',\n",
       "       'TIPI1', 'TIPI2', 'TIPI3', 'TIPI4', 'TIPI5', 'TIPI6', 'TIPI7', 'TIPI8',\n",
       "       'TIPI9', 'TIPI10', 'age', 'familysize', 'major', 'GCB', 'validity',\n",
       "       'vocabulary_knowledge', 'STEM', 'HUM', 'BUS', 'OTHER', 'ART',\n",
       "       'education_1', 'education_2', 'education_3', 'education_4', 'urban_1',\n",
       "       'urban_2', 'urban_3', 'gender_1', 'gender_2', 'gender_3', 'engnat_1',\n",
       "       'engnat_2', 'hand_1', 'hand_2', 'hand_3', 'religion_1', 'religion_2',\n",
       "       'religion_3', 'religion_4', 'religion_5', 'religion_6', 'religion_7',\n",
       "       'religion_8', 'religion_9', 'religion_10', 'religion_11', 'religion_12',\n",
       "       'orientation_1', 'orientation_2', 'orientation_3', 'orientation_4',\n",
       "       'orientation_5', 'race_1', 'race_2', 'race_3', 'race_4', 'race_5',\n",
       "       'voted_1', 'voted_2', 'married_1', 'married_2', 'married_3',\n",
       "       'constant'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"conspiracy_theories_data_orig.csv\")\n",
    "verbose = False\n",
    "# Only NaN values are in \"major\" column, so no other cleaning is necessary\n",
    "# Benefit of working with survey data as opposed to data collected using messier methods\n",
    "# TODO: check for survey responses that don't make sense (answered just the default answer for all \n",
    "# questions); these should be thrown out\n",
    "\n",
    "# Measure for General Conspiracy Belief. Normalized average of responses to questions 1-15 of survey\n",
    "df['GCB'] = df[['Q'+str(i) for i in range(1, 16)]].mean(axis=1) / 5\n",
    "df.drop(columns=['Q'+str(i) for i in range(1, 16)], inplace=True)\n",
    "\n",
    "# The survey asked participants what words they knew. Columns VCL6, VCL9, VCL12 were not real words, and were included in \n",
    "# order to perform a validity check\n",
    "\n",
    "df['validity'] = df[['VCL6', 'VCL9', 'VCL12']].mean(axis=1)\n",
    "# Score how many vocab questions the respondent answered correctly. 0 is correct for VCL 6, 9, 12, and 1 is correct for all others.\n",
    "\n",
    "# df['vocabulary_knowledge'] = (df[['VCL' + str(i) for i in [1, 2, 3, 4, 5, 7, 8, 10, 11, 13, 14, 15, 16]]] \n",
    "#                               + (1 - df[['VCL' + str(i) for i in [6,9,12]]])).mean(axis=1)\n",
    "\n",
    "df['vocabulary_knowledge'] = (df[['VCL' + str(i) for i in [1, 2, 3, 4, 5, 7, 8, 10, 11, 13, 14, 15, 16]]]).mean(axis=1) \n",
    "\n",
    "df.drop(columns=['VCL'+str(i) for i in range(1, 17)], inplace=True)\n",
    "\n",
    "#I split up every instance of \"major\" to a category: HUM (Humanities), BUS (business/law), ART, STEM, and OTHER. \n",
    "#This block creates a one-hot encoding for each of these.\n",
    "names = [\"STEM\", \"HUM\", \"BUS\", \"OTHER\", \"ART\"]\n",
    "for name in names:\n",
    "    # For each category, there is a file of strings of majors that should be classified as that category\n",
    "    # Read in the corresponding file\n",
    "    tf = open(f\"{name}.txt\", \"r\",newline='\\n')\n",
    "    # Grab all the strings in the file\n",
    "    majors = [i[:-2] for i in tf.readlines()]\n",
    "    def func(x): # If string is in the list of majors, return a 1, else a 0\n",
    "        return int(x in majors)\n",
    "    func = np.vectorize(func)\n",
    "    df[name] = 1 \n",
    "    df[name] = df.major.apply(func) # Create  a new column with the one hot encoding for the given category\n",
    "    \n",
    "# One hot encode the other features\n",
    "categorical_columns = ['education','urban', 'gender', 'engnat', 'hand', 'religion', 'orientation','race', 'voted', 'married']\n",
    "df = pd.get_dummies(df, columns=categorical_columns, drop_first=True)\n",
    "df[\"constant\"] = 1\n",
    "df.columns\n",
    "# The columns 'TIPI1', 'TIPI2', 'TIPI3', 'TIPI4', 'TIPI5', 'TIPI6', 'TIPI7', 'TIPI8',\n",
    "#        'TIPI9', 'TIPI10', 'age', 'familysize', 'major', 'GCB', 'validity',\n",
    "#        'vocabulary_knowledge', 'STEM', 'HUM', 'BUS', 'OTHER', 'ART',\n",
    "#        'education_1', 'education_2', 'education_3', 'education_4', 'urban_1',\n",
    "#        'urban_2', 'urban_3', 'gender_1', 'gender_2', 'gender_3', 'engnat_1',\n",
    "#        'engnat_2', 'hand_1', 'hand_2', 'hand_3', 'religion_1', 'religion_2',\n",
    "#        'religion_3', 'religion_4', 'religion_5', 'religion_6', 'religion_7',\n",
    "#        'religion_8', 'religion_9', 'religion_10', 'religion_11', 'religion_12',\n",
    "#        'orientation_1', 'orientation_2', 'orientation_3', 'orientation_4',\n",
    "#        'orientation_5', 'race_1', 'race_2', 'race_3', 'race_4', 'race_5',\n",
    "#        'voted_1', 'voted_2', 'married_1', 'married_2', 'married_3',\n",
    "#        'constant'\n",
    "# are all fair game for regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.846154\n",
       "1       0.692308\n",
       "2       1.000000\n",
       "3       0.846154\n",
       "4       0.692308\n",
       "          ...   \n",
       "2490    1.000000\n",
       "2491    0.769231\n",
       "2492    0.769231\n",
       "2493    0.615385\n",
       "2494    0.384615\n",
       "Name: vocabulary_knowledge, Length: 2495, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Are there any rows where the user just answered the same for all relevant questions? \n",
    "# Are there any rows that were only partially completed? \n",
    "    # For the above two, could look at time to complete survey\n",
    "# TODO: One-hot encode the rest of the categorical data\n",
    "df[\"vocabulary_knowledge\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Surveys that took over an hour to take (including landing pad time)\n",
      "64\n",
      "# Surveys that took over an hour to take (excluding landing pad time)\n",
      "20\n",
      "# Surveys that spent over an hour on the landing pad\n",
      "44\n"
     ]
    }
   ],
   "source": [
    "# df[\"introelapse\"].hist()\n",
    "df[\"total_time_taken_(mins)\"] = (df[\"introelapse\"] + df[\"testelapse\"] + df[\"surveyelapse\"])/60\n",
    "df[\"total_survey_time_taken_(mins)\"] = (df[\"testelapse\"] + df[\"surveyelapse\"])/60\n",
    "\n",
    "print(\"# Surveys that took over an hour to take (including landing pad time)\")\n",
    "print(sum(df[\"total_time_taken_(mins)\"] >= 60))\n",
    "\n",
    "print(\"# Surveys that took over an hour to take (excluding landing pad time)\")\n",
    "print(sum(df[\"total_survey_time_taken_(mins)\"] >= 60))\n",
    "\n",
    "print(\"# Surveys that spent over an hour on the landing pad\")\n",
    "print(sum(df[\"introelapse\"]/60 >= 60))\n",
    "\n",
    "if verbose: \n",
    "    df[\"total_time_taken_(mins)\"][df[\"total_time_taken_(mins)\"] < 60].hist()\n",
    "    plt.subplots()\n",
    "    df[\"total_survey_time_taken_(mins)\"][df[\"total_survey_time_taken_(mins)\"] < 60].hist()\n",
    "    plt.subplots()\n",
    "    df[\"introelapse\"][df[\"introelapse\"] < 60].hist()\n",
    "\n",
    "# Even though these surveys took a lot longer than seems reasonable, there are no clear indications in the \n",
    "# subjects' answers that any of these responses should be dropped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if verbose: \n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "        display(df[df[\"introelapse\"]/60 >= 60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the 50 fastest responses\n",
    "if verbose:\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "        display(df.sort_values(by=\"total_time_taken_(mins)\")[:50])\n",
    "    \n",
    "# Again, none of these look totally wrong. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Rows with matching entries in columsn Q1, Q2, ..., Q15\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9', 'Q10', 'Q11',\\n       'Q12', 'Q13', 'Q14', 'Q15'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-bd99914f5fa6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Did any respondents put the same thing for each question in the GCB inventory?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"# Rows with matching entries in columsn Q1, Q2, ..., Q15\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Q\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moption_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'display.max_rows'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'display.max_columns'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3462\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3463\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3464\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3466\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1312\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1314\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis)\u001b[0m\n\u001b[0;32m   1372\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0muse_interval_msg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1374\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1376\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9', 'Q10', 'Q11',\\n       'Q12', 'Q13', 'Q14', 'Q15'],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# Did any respondents put the same thing for each question in the GCB inventory? \n",
    "print(\"# Rows with matching entries in columsn Q1, Q2, ..., Q15\")\n",
    "print(sum(df[[\"Q\" + str(i) for i in range(1, 16)]].apply(lambda x: min(x) == max(x), 1)))\n",
    "if verbose:\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "        display(df[df[[\"Q\" + str(i) for i in range(1, 16)]].apply(lambda x: min(x) == max(x), 1)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    GCB   R-squared:                       0.160\n",
      "Model:                            OLS   Adj. R-squared:                  0.155\n",
      "Method:                 Least Squares   F-statistic:                     29.60\n",
      "Date:                Mon, 15 Nov 2021   Prob (F-statistic):           1.99e-82\n",
      "Time:                        12:06:43   Log-Likelihood:                 610.82\n",
      "No. Observations:                2495   AIC:                            -1188.\n",
      "Df Residuals:                    2478   BIC:                            -1089.\n",
      "Df Model:                          16                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "TIPI1                    0.0044      0.002      2.245      0.025       0.001       0.008\n",
      "TIPI2                    0.0118      0.002      5.514      0.000       0.008       0.016\n",
      "TIPI9                   -0.0032      0.002     -1.526      0.127      -0.007       0.001\n",
      "validity                 0.0957      0.017      5.491      0.000       0.062       0.130\n",
      "vocabulary_knowledge    -0.2019      0.024     -8.254      0.000      -0.250      -0.154\n",
      "STEM                    -0.0314      0.010     -3.191      0.001      -0.051      -0.012\n",
      "education_2              0.0300      0.008      3.755      0.000       0.014       0.046\n",
      "urban_3                  0.0234      0.008      2.894      0.004       0.008       0.039\n",
      "gender_1                -0.0184      0.008     -2.256      0.024      -0.034      -0.002\n",
      "religion_2              -0.0715      0.009     -7.967      0.000      -0.089      -0.054\n",
      "religion_7               0.0520      0.014      3.664      0.000       0.024       0.080\n",
      "religion_12              0.0990      0.012      8.048      0.000       0.075       0.123\n",
      "orientation_5            0.0396      0.017      2.344      0.019       0.006       0.073\n",
      "voted_2                  0.0189      0.008      2.261      0.024       0.003       0.035\n",
      "married_2                0.0401      0.011      3.617      0.000       0.018       0.062\n",
      "married_3                0.0621      0.017      3.562      0.000       0.028       0.096\n",
      "const                    0.6477      0.026     24.578      0.000       0.596       0.699\n",
      "==============================================================================\n",
      "Omnibus:                       62.145   Durbin-Watson:                   1.928\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               33.743\n",
      "Skew:                           0.087   Prob(JB):                     4.71e-08\n",
      "Kurtosis:                       2.458   Cond. No.                         66.7\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-90c8b556a647>:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['const'] = df['constant']\n"
     ]
    }
   ],
   "source": [
    "y = df['GCB']\n",
    "X = df.drop(columns=['GCB', 'major'])\n",
    "#with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "#        display(X)\n",
    "#np_X = np.array(X, dtype=float)\n",
    "\n",
    "# Run a L1-regularization to see which features we should keep and what we can get rid of\n",
    "lamb_list = np.geomspace(10**-10, 10**5, 16)\n",
    "\n",
    "# Go through each lambda\n",
    "#for lamb in lamb_list:\n",
    "model = lm.OLS(y, X).fit_regularized(alpha=1e-3, L1_wt=1)\n",
    "beta = model.params\n",
    "nonzero = np.abs(beta) > 0.01\n",
    "X = X[X.columns[nonzero.values]]\n",
    "X['const'] = df['constant']\n",
    "X = X.drop(columns=['TIPI4', 'TIPI6', 'TIPI7', 'engnat_1', 'gender_2'])\n",
    "model = lm.OLS(y, X).fit()\n",
    "print(model.summary())\n",
    "#print(X.columns)\n",
    "#print('For lambda = ' + str(lamb) + '.\\tNonzero features = ' + str(np.sum(nonzero)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
