{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import statsmodels.regression.linear_model as lm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data and Engineer Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"data/\"\n",
    "df = pd.read_csv(data_directory + \"conspiracy_theories_data_orig.csv\")\n",
    "verbose = False\n",
    "# Only NaN values are in \"major\" column, so no other cleaning is necessary to remove NaN values\n",
    "# Benefit of working with survey data as opposed to data collected using messier methods\n",
    "\n",
    "# Measure for General Conspiracy Belief. Normalized average of responses to questions 1-15 of survey\n",
    "df['GCB'] = df[['Q'+str(i) for i in range(1, 16)]].mean(axis=1) / 5\n",
    "\n",
    "# Score how many vocab questions the respondent answered correctly. 0 is correct for VCL 6, 9, 12, and 1 is correct for all others.\n",
    "df['vocabulary_knowledge'] = pd.concat((df[['VCL' + str(i) for i in [1, 2, 3, 4, 5, 7, 8, 10, 11, 13, 14, 15, 16]]], \n",
    "                                        (1 - df[['VCL' + str(i) for i in [6,9,12]]])), axis=1).mean(axis=1)\n",
    "\n",
    "# The survey asked participants what words they knew. Columns VCL6, VCL9, VCL12 were not real words, and were included in \n",
    "# order to perform a validity check\n",
    "df['vocabulary_misclassification'] = df[['VCL6', 'VCL9', 'VCL12']].mean(axis=1)\n",
    "\n",
    "# Split up every instance of \"major\" to a category: HUM (Humanities), BUS (business/law), ART, STEM, and OTHER. \n",
    "# This block creates a one-hot encoding for each of these.\n",
    "names = [\"STEM\", \"HUM\", \"BUS\", \"OTHER\", \"ART\"]\n",
    "for name in names:\n",
    "    # For each category, there is a file of strings of majors that should be classified as that category\n",
    "    # Read in the corresponding file\n",
    "    tf = open(data_directory + f\"{name}.txt\", \"r\",newline='\\n')\n",
    "    # Grab all the strings in the file\n",
    "    majors = [i[:-2] for i in tf.readlines()]\n",
    "    def func(x): # If string is in the list of majors, return a 1, else a 0\n",
    "        return int(x in majors)\n",
    "    func = np.vectorize(func)\n",
    "    df[name] = 1 \n",
    "    df[name] = df.major.apply(func) # Create  a new column with the one hot encoding for the given category\n",
    "    \n",
    "# One hot encode the other categorical features\n",
    "categorical_columns = ['education','urban', 'gender', 'engnat', 'hand', 'religion', 'orientation','race', 'voted', 'married']\n",
    "df = pd.get_dummies(df, columns=categorical_columns, drop_first=True)\n",
    "df[\"constant\"] = 1\n",
    "\n",
    "# Engineer some features about the time taken on the survey for reviewing edge cases (not to be used in regression).\n",
    "df[\"total_time_taken_(mins)\"] = (df[\"introelapse\"] + df[\"testelapse\"] + df[\"surveyelapse\"])/60\n",
    "df[\"total_survey_time_taken_(mins)\"] = (df[\"testelapse\"] + df[\"surveyelapse\"])/60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review Edge Cases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Surveys that took over an hour to take (including landing pad time)\n",
      "64\n",
      "# Surveys that took over an hour to take (excluding landing pad time)\n",
      "20\n",
      "# Surveys that spent over an hour on the landing pad\n",
      "44\n"
     ]
    }
   ],
   "source": [
    "print(\"# Surveys that took over an hour to take (including landing pad time)\")\n",
    "print(sum(df[\"total_time_taken_(mins)\"] >= 60))\n",
    "\n",
    "print(\"# Surveys that took over an hour to take (excluding landing pad time)\")\n",
    "print(sum(df[\"total_survey_time_taken_(mins)\"] >= 60))\n",
    "\n",
    "print(\"# Surveys that spent over an hour on the landing pad\")\n",
    "print(sum(df[\"introelapse\"]/60 >= 60))\n",
    "\n",
    "if verbose: \n",
    "    df[\"total_time_taken_(mins)\"][df[\"total_time_taken_(mins)\"] < 60].hist()\n",
    "    plt.subplots()\n",
    "    df[\"total_survey_time_taken_(mins)\"][df[\"total_survey_time_taken_(mins)\"] < 60].hist()\n",
    "    plt.subplots()\n",
    "    df[\"introelapse\"][df[\"introelapse\"] < 60].hist()\n",
    "\n",
    "# Even though these surveys took a lot longer than seems reasonable, there are no clear indications in the \n",
    "# subjects' answers that any of these responses should be dropped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "if verbose: \n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "        display(df[df[\"introelapse\"]/60 >= 60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the 50 fastest responses\n",
    "if verbose:\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "        display(df.sort_values(by=\"total_time_taken_(mins)\")[:50])\n",
    "    \n",
    "# Again, none of these look responses have any obvious indications that they should be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Rows with matching entries in columsn Q1, Q2, ..., Q15\n",
      "98\n"
     ]
    }
   ],
   "source": [
    "# Did any respondents put the same thing for each question in the GCB inventory? \n",
    "print(\"# Rows with matching entries in columsn Q1, Q2, ..., Q15\")\n",
    "print(sum(df[[\"Q\" + str(i) for i in range(1, 16)]].apply(lambda x: min(x) == max(x), 1)))\n",
    "if verbose:\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "        display(df[df[[\"Q\" + str(i) for i in range(1, 16)]].apply(lambda x: min(x) == max(x), 1)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis and Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all the columns that are used for feature engineering and cleaning.\n",
    "df.drop(columns=['Q'+str(i) for i in range(1, 16)], inplace=True) # Drop the specific question information from which GCB is computed\n",
    "df.drop(columns=['E'+str(i) for i in range(1, 16)], inplace=True) # Timing information\n",
    "df.drop(columns=['VCL'+str(i) for i in range(1, 17)], inplace=True) # Specific vocabulary questions, rolled into \n",
    "df.drop(columns=['total_time_taken_(mins)', 'total_survey_time_taken_(mins)', \n",
    "                 'introelapse', 'surveyelapse', 'testelapse'], inplace=True)\n",
    "df.drop(columns=['major'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    GCB   R-squared:                       0.139\n",
      "Model:                            OLS   Adj. R-squared:                  0.133\n",
      "Method:                 Least Squares   F-statistic:                     22.29\n",
      "Date:                Wed, 17 Nov 2021   Prob (F-statistic):           3.82e-68\n",
      "Time:                        12:32:12   Log-Likelihood:                 579.98\n",
      "No. Observations:                2495   AIC:                            -1122.\n",
      "Df Residuals:                    2476   BIC:                            -1011.\n",
      "Df Model:                          18                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================================\n",
      "                                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------------\n",
      "TIPI2                            0.0142      0.002      6.565      0.000       0.010       0.018\n",
      "TIPI5                            0.0056      0.003      2.008      0.045       0.000       0.011\n",
      "TIPI6                           -0.0014      0.002     -0.670      0.503      -0.006       0.003\n",
      "vocabulary_misclassification     0.0706      0.017      4.051      0.000       0.036       0.105\n",
      "STEM                            -0.0383      0.010     -3.774      0.000      -0.058      -0.018\n",
      "education_2                      0.0380      0.009      4.120      0.000       0.020       0.056\n",
      "education_3                      0.0088      0.011      0.812      0.417      -0.012       0.030\n",
      "urban_3                          0.0242      0.008      2.882      0.004       0.008       0.041\n",
      "gender_2                         0.0219      0.008      2.707      0.007       0.006       0.038\n",
      "engnat_1                         0.0061      0.009      0.653      0.514      -0.012       0.025\n",
      "religion_2                      -0.0753      0.009     -8.266      0.000      -0.093      -0.057\n",
      "religion_3                       0.0873      0.028      3.119      0.002       0.032       0.142\n",
      "religion_7                       0.0603      0.014      4.179      0.000       0.032       0.089\n",
      "religion_12                      0.0996      0.013      7.947      0.000       0.075       0.124\n",
      "orientation_2                   -0.0120      0.011     -1.130      0.259      -0.033       0.009\n",
      "orientation_5                    0.0431      0.017      2.525      0.012       0.010       0.077\n",
      "voted_2                          0.0260      0.009      3.022      0.003       0.009       0.043\n",
      "married_1                       -0.0284      0.010     -2.842      0.005      -0.048      -0.009\n",
      "constant                         0.2304      0.013     17.307      0.000       0.204       0.257\n",
      "const                            0.2304      0.013     17.307      0.000       0.204       0.257\n",
      "==============================================================================\n",
      "Omnibus:                       85.135   Durbin-Watson:                   1.925\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               42.486\n",
      "Skew:                           0.107   Prob(JB):                     5.95e-10\n",
      "Kurtosis:                       2.398   Cond. No.                     1.16e+17\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.54e-29. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cb/6sp2ghhj1c99ysqvww0hq3m80000gn/T/ipykernel_7612/1618786671.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['const'] = df['constant']\n"
     ]
    }
   ],
   "source": [
    "y = df['GCB']\n",
    "X = df.drop(columns=['GCB'])\n",
    "\n",
    "# Run a L1-regularization to see which features we should keep and what we can get rid of\n",
    "lamb_list = np.geomspace(10**-10, 10**5, 16)\n",
    "\n",
    "# Go through each lambda\n",
    "#for lamb in lamb_list:\n",
    "model = lm.OLS(y, X).fit_regularized(alpha=1e-3, L1_wt=1)\n",
    "beta = model.params\n",
    "nonzero = np.abs(beta) > 0.01\n",
    "X = X[X.columns[nonzero.values]]\n",
    "X['const'] = df['constant']\n",
    "# X = X.drop(columns=['TIPI4', 'TIPI6', 'TIPI7', 'engnat_1', 'gender_2'])\n",
    "model = lm.OLS(y, X).fit()\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TIPI1                              0\n",
       "TIPI2                              0\n",
       "TIPI3                              0\n",
       "TIPI4                              0\n",
       "TIPI5                              0\n",
       "TIPI6                              0\n",
       "TIPI7                              0\n",
       "TIPI8                              0\n",
       "TIPI9                              0\n",
       "TIPI10                             0\n",
       "age                                0\n",
       "familysize                         0\n",
       "vocabulary_knowledge            2495\n",
       "vocabulary_misclassification       0\n",
       "STEM                               0\n",
       "HUM                                0\n",
       "BUS                                0\n",
       "OTHER                              0\n",
       "ART                                0\n",
       "education_1                        0\n",
       "education_2                        0\n",
       "education_3                        0\n",
       "education_4                        0\n",
       "urban_1                            0\n",
       "urban_2                            0\n",
       "urban_3                            0\n",
       "gender_1                           0\n",
       "gender_2                           0\n",
       "gender_3                           0\n",
       "engnat_1                           0\n",
       "engnat_2                           0\n",
       "hand_1                             0\n",
       "hand_2                             0\n",
       "hand_3                             0\n",
       "religion_1                         0\n",
       "religion_2                         0\n",
       "religion_3                         0\n",
       "religion_4                         0\n",
       "religion_5                         0\n",
       "religion_6                         0\n",
       "religion_7                         0\n",
       "religion_8                         0\n",
       "religion_9                         0\n",
       "religion_10                        0\n",
       "religion_11                        0\n",
       "religion_12                        0\n",
       "orientation_1                      0\n",
       "orientation_2                      0\n",
       "orientation_3                      0\n",
       "orientation_4                      0\n",
       "orientation_5                      0\n",
       "race_1                             0\n",
       "race_2                             0\n",
       "race_3                             0\n",
       "race_4                             0\n",
       "race_5                             0\n",
       "voted_1                            0\n",
       "voted_2                            0\n",
       "married_1                          0\n",
       "married_2                          0\n",
       "married_3                          0\n",
       "constant                           0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(X.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snowflakes",
   "language": "python",
   "name": "snowflakes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
