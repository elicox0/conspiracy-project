{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import statsmodels.regression.linear_model as lm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data and Engineer Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"data/\"\n",
    "df = pd.read_csv(data_directory + \"conspiracy_theories_data_orig.csv\")\n",
    "verbose = False\n",
    "# Only NaN values are in \"major\" column, so no other cleaning is necessary to remove NaN values\n",
    "# Benefit of working with survey data as opposed to data collected using messier methods\n",
    "\n",
    "# Measure for General Conspiracy Belief. Normalized average of responses to questions 1-15 of survey\n",
    "df['GCB'] = df[['Q'+str(i) for i in range(1, 16)]].mean(axis=1) / 5\n",
    "\n",
    "# Score how many vocab questions the respondent answered correctly. 0 is correct for VCL 6, 9, 12, and 1 is correct for all others.\n",
    "df['vocabulary_knowledge'] = pd.concat((df[['VCL' + str(i) for i in [1, 2, 3, 4, 5, 7, 8, 10, 11, 13, 14, 15, 16]]], \n",
    "                                        (1 - df[['VCL' + str(i) for i in [6,9,12]]])), axis=1).mean(axis=1)\n",
    "\n",
    "# The survey asked participants what words they knew. Columns VCL6, VCL9, VCL12 were not real words, and were included in \n",
    "# order to perform a validity check\n",
    "df['vocabulary_misclassification'] = df[['VCL6', 'VCL9', 'VCL12']].mean(axis=1)\n",
    "\n",
    "# Split up every instance of \"major\" to a category: HUM (Humanities), BUS (business/law), ART, STEM, and OTHER. \n",
    "# This block creates a one-hot encoding for each of these.\n",
    "names = [\"STEM\", \"HUM\", \"BUS\", \"OTHER\", \"ART\"]\n",
    "for name in names:\n",
    "    # For each category, there is a file of strings of majors that should be classified as that category\n",
    "    # Read in the corresponding file\n",
    "    tf = open(data_directory + f\"{name}.txt\", \"r\",newline='\\n')\n",
    "    # Grab all the strings in the file\n",
    "    majors = [i[:-2] for i in tf.readlines()]\n",
    "    def func(x): # If string is in the list of majors, return a 1, else a 0\n",
    "        return int(x in majors)\n",
    "    func = np.vectorize(func)\n",
    "    df[name] = 1 \n",
    "    df[name] = df.major.apply(func) # Create  a new column with the one hot encoding for the given category\n",
    "    \n",
    "# One hot encode the other categorical features\n",
    "categorical_columns = ['education','urban', 'gender', 'engnat', 'hand', 'religion', 'orientation','race', 'voted', 'married']\n",
    "df = pd.get_dummies(df, columns=categorical_columns, drop_first=True)\n",
    "df[\"constant\"] = 1\n",
    "\n",
    "# Engineer some features about the time taken on the survey for reviewing edge cases (not to be used in regression).\n",
    "df[\"total_time_taken_(mins)\"] = (df[\"introelapse\"] + df[\"testelapse\"] + df[\"surveyelapse\"])/60\n",
    "df[\"total_survey_time_taken_(mins)\"] = (df[\"testelapse\"] + df[\"surveyelapse\"])/60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review Edge Cases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Surveys that took over an hour to take (including landing pad time)\n",
      "64\n",
      "# Surveys that took over an hour to take (excluding landing pad time)\n",
      "20\n",
      "# Surveys that spent over an hour on the landing pad\n",
      "44\n"
     ]
    }
   ],
   "source": [
    "print(\"# Surveys that took over an hour to take (including landing pad time)\")\n",
    "print(sum(df[\"total_time_taken_(mins)\"] >= 60))\n",
    "\n",
    "print(\"# Surveys that took over an hour to take (excluding landing pad time)\")\n",
    "print(sum(df[\"total_survey_time_taken_(mins)\"] >= 60))\n",
    "\n",
    "print(\"# Surveys that spent over an hour on the landing pad\")\n",
    "print(sum(df[\"introelapse\"]/60 >= 60))\n",
    "\n",
    "if verbose: \n",
    "    df[\"total_time_taken_(mins)\"][df[\"total_time_taken_(mins)\"] < 60].hist()\n",
    "    plt.subplots()\n",
    "    df[\"total_survey_time_taken_(mins)\"][df[\"total_survey_time_taken_(mins)\"] < 60].hist()\n",
    "    plt.subplots()\n",
    "    df[\"introelapse\"][df[\"introelapse\"] < 60].hist()\n",
    "\n",
    "# Even though these surveys took a lot longer than seems reasonable, there are no clear indications in the \n",
    "# subjects' answers that any of these responses should be dropped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if verbose: \n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "        display(df[df[\"introelapse\"]/60 >= 60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the 50 fastest responses\n",
    "if verbose:\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "        display(df.sort_values(by=\"total_time_taken_(mins)\")[:50])\n",
    "    \n",
    "# Again, none of these look responses have any obvious indications that they should be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Rows with matching entries in columsn Q1, Q2, ..., Q15\n",
      "98\n"
     ]
    }
   ],
   "source": [
    "# Did any respondents put the same thing for each question in the GCB inventory? \n",
    "print(\"# Rows with matching entries in columsn Q1, Q2, ..., Q15\")\n",
    "print(sum(df[[\"Q\" + str(i) for i in range(1, 16)]].apply(lambda x: min(x) == max(x), 1)))\n",
    "if verbose:\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "        display(df[df[[\"Q\" + str(i) for i in range(1, 16)]].apply(lambda x: min(x) == max(x), 1)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis and Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all the columns that are used for feature engineering and cleaning.\n",
    "df.drop(columns=['Q'+str(i) for i in range(1, 16)], inplace=True) # Drop the specific question information from which GCB is computed\n",
    "df.drop(columns=['E'+str(i) for i in range(1, 16)], inplace=True) # Timing information\n",
    "df.drop(columns=['VCL'+str(i) for i in range(1, 17)], inplace=True) # Specific vocabulary questions, rolled into \n",
    "df.drop(columns=['total_time_taken_(mins)', 'total_survey_time_taken_(mins)', \n",
    "                 'introelapse', 'surveyelapse', 'testelapse'], inplace=True)\n",
    "df.drop(columns=['major'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{center}\n",
      "\\begin{tabular}{lclc}\n",
      "\\toprule\n",
      "\\textbf{Dep. Variable:}                &       GCB        & \\textbf{  R-squared:         } &     0.139   \\\\\n",
      "\\textbf{Model:}                        &       OLS        & \\textbf{  Adj. R-squared:    } &     0.133   \\\\\n",
      "\\textbf{Method:}                       &  Least Squares   & \\textbf{  F-statistic:       } &     22.29   \\\\\n",
      "\\textbf{Date:}                         & Wed, 17 Nov 2021 & \\textbf{  Prob (F-statistic):} &  3.82e-68   \\\\\n",
      "\\textbf{Time:}                         &     12:41:16     & \\textbf{  Log-Likelihood:    } &    579.98   \\\\\n",
      "\\textbf{No. Observations:}             &        2495      & \\textbf{  AIC:               } &    -1122.   \\\\\n",
      "\\textbf{Df Residuals:}                 &        2476      & \\textbf{  BIC:               } &    -1011.   \\\\\n",
      "\\textbf{Df Model:}                     &          18      & \\textbf{                     } &             \\\\\n",
      "\\textbf{Covariance Type:}              &    nonrobust     & \\textbf{                     } &             \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\begin{tabular}{lcccccc}\n",
      "                                       & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
      "\\midrule\n",
      "\\textbf{TIPI2}                         &       0.0142  &        0.002     &     6.565  &         0.000        &        0.010    &        0.018     \\\\\n",
      "\\textbf{TIPI5}                         &       0.0056  &        0.003     &     2.008  &         0.045        &        0.000    &        0.011     \\\\\n",
      "\\textbf{TIPI6}                         &      -0.0014  &        0.002     &    -0.670  &         0.503        &       -0.006    &        0.003     \\\\\n",
      "\\textbf{vocabulary\\_misclassification} &       0.0706  &        0.017     &     4.051  &         0.000        &        0.036    &        0.105     \\\\\n",
      "\\textbf{STEM}                          &      -0.0383  &        0.010     &    -3.774  &         0.000        &       -0.058    &       -0.018     \\\\\n",
      "\\textbf{education\\_2}                  &       0.0380  &        0.009     &     4.120  &         0.000        &        0.020    &        0.056     \\\\\n",
      "\\textbf{education\\_3}                  &       0.0088  &        0.011     &     0.812  &         0.417        &       -0.012    &        0.030     \\\\\n",
      "\\textbf{urban\\_3}                      &       0.0242  &        0.008     &     2.882  &         0.004        &        0.008    &        0.041     \\\\\n",
      "\\textbf{gender\\_2}                     &       0.0219  &        0.008     &     2.707  &         0.007        &        0.006    &        0.038     \\\\\n",
      "\\textbf{engnat\\_1}                     &       0.0061  &        0.009     &     0.653  &         0.514        &       -0.012    &        0.025     \\\\\n",
      "\\textbf{religion\\_2}                   &      -0.0753  &        0.009     &    -8.266  &         0.000        &       -0.093    &       -0.057     \\\\\n",
      "\\textbf{religion\\_3}                   &       0.0873  &        0.028     &     3.119  &         0.002        &        0.032    &        0.142     \\\\\n",
      "\\textbf{religion\\_7}                   &       0.0603  &        0.014     &     4.179  &         0.000        &        0.032    &        0.089     \\\\\n",
      "\\textbf{religion\\_12}                  &       0.0996  &        0.013     &     7.947  &         0.000        &        0.075    &        0.124     \\\\\n",
      "\\textbf{orientation\\_2}                &      -0.0120  &        0.011     &    -1.130  &         0.259        &       -0.033    &        0.009     \\\\\n",
      "\\textbf{orientation\\_5}                &       0.0431  &        0.017     &     2.525  &         0.012        &        0.010    &        0.077     \\\\\n",
      "\\textbf{voted\\_2}                      &       0.0260  &        0.009     &     3.022  &         0.003        &        0.009    &        0.043     \\\\\n",
      "\\textbf{married\\_1}                    &      -0.0284  &        0.010     &    -2.842  &         0.005        &       -0.048    &       -0.009     \\\\\n",
      "\\textbf{constant}                      &       0.2304  &        0.013     &    17.307  &         0.000        &        0.204    &        0.257     \\\\\n",
      "\\textbf{const}                         &       0.2304  &        0.013     &    17.307  &         0.000        &        0.204    &        0.257     \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\begin{tabular}{lclc}\n",
      "\\textbf{Omnibus:}       & 85.135 & \\textbf{  Durbin-Watson:     } &    1.925  \\\\\n",
      "\\textbf{Prob(Omnibus):} &  0.000 & \\textbf{  Jarque-Bera (JB):  } &   42.486  \\\\\n",
      "\\textbf{Skew:}          &  0.107 & \\textbf{  Prob(JB):          } & 5.95e-10  \\\\\n",
      "\\textbf{Kurtosis:}      &  2.398 & \\textbf{  Cond. No.          } & 5.64e+17  \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "%\\caption{OLS Regression Results}\n",
      "\\end{center}\n",
      "\n",
      "Notes: \\newline\n",
      " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
      " [2] The smallest eigenvalue is 6.51e-31. This might indicate that there are \\newline\n",
      " strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16179/1123611876.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['const'] = df['constant']\n"
     ]
    }
   ],
   "source": [
    "y = df['GCB']\n",
    "X = df.drop(columns=['GCB'])\n",
    "\n",
    "# Run a L1-regularization to see which features we should keep and what we can get rid of\n",
    "lamb_list = np.geomspace(10**-10, 10**5, 16)\n",
    "\n",
    "# Go through each lambda\n",
    "#for lamb in lamb_list:\n",
    "model = lm.OLS(y, X).fit_regularized(alpha=1e-3, L1_wt=1)\n",
    "beta = model.params\n",
    "nonzero = np.abs(beta) > 0.01\n",
    "X = X[X.columns[nonzero.values]]\n",
    "X['const'] = df['constant']\n",
    "# X = X.drop(columns=['TIPI4', 'TIPI6', 'TIPI7', 'engnat_1', 'gender_2'])\n",
    "model = lm.OLS(y, X).fit()\n",
    "print(model.summary().as_latex())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TIPI2                           0\n",
       "TIPI5                           0\n",
       "TIPI6                           0\n",
       "vocabulary_misclassification    0\n",
       "STEM                            0\n",
       "education_2                     0\n",
       "education_3                     0\n",
       "urban_3                         0\n",
       "gender_2                        0\n",
       "engnat_1                        0\n",
       "religion_2                      0\n",
       "religion_3                      0\n",
       "religion_7                      0\n",
       "religion_12                     0\n",
       "orientation_2                   0\n",
       "orientation_5                   0\n",
       "voted_2                         0\n",
       "married_1                       0\n",
       "constant                        0\n",
       "const                           0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(X.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
